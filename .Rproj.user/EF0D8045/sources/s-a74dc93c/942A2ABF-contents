---
title: 'Event-related potentials: why and how'
author: ''
date: '2017-01-01'
slug: event-related-potentials-why-and-how
categories:
  - event-related potentials
tags:
  - event-related potentials
  - electroencephalography
  - methodology
  - cognitive neuroscience
  - psycholinguistics
subtitle: ''
summary: ''
authors: []
lastmod: ''
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---


Event-related potentials, or ERPs, offer a unique insight in the study of how the brain helps us think. 

ERPs are lectrical responses in the brain triggered by, and time-locked to, a specific stimulus in an experiment. Researchers are typically interested in specific *components* of the ERP signal, which are consistently found at specific points in the time course of a cognitive process. Multiple components have been identified over the last decades. Each component is characterised in a number of dimensions, described below.

**1. Polarity:** the 

latency denotes the point in time when the ERP typically appears

- scalp distribution: the area of the brain 

. For instance, in language, the N400 component has been consistently identified as an effort to process the meaning of words or sentences. Time-wise, the N400 is characterised  . Other examples include lateralized readiness potentials, signalling motor preparation (Mordkoff & Gianaros, 2000), and the P3b component, which appears in the context of responses, and is thus relevant to researchers across domains (van Vliet et al., 2014); .


## Time course of word processing 

The association of earlier semantic processes to a greater relevance for comprehension is supported by some evidence. In a nutshell, broader processes start only after more immediate ones have started. The most immediate process is the recognition of a string of letters as a word, which seems to start within 90 ms post word onset in early auditory cortex and the Visual Word Form Area (Willems, Frank, Nijhoff, Hagoort, & van den Bosch, 2016). Broader lexical and semantic processes ensue then, namely, identification of the word as a known word within around 160 ms, and access to its meaning within around 200 ms (Hauk, 2016). These processes may overlap, as the sensitivity of the N400 to both suggests (Kutas & Federmeier, 2011). They also likely extend further in the processing timeline, albeit with a lesser role. The lexical and semantic stages are directly relevant to our current topic, as shown in studies with different processing tasks. Tasks promoting semantic processing seem to engage embodied systems more than lexical tasks do (Sato, Mengarelli, Riggio, Gallese, & Buccino, 2008). 

Once the lexical and semantic stages have emerged, post-lexical, post-semantic processes will emerge. These are mental imagery and episodic memory processes—both with an approximate emergence around 270 ms after word onset. The gradual progression from the identification of a word up to accessing its broadest meaning is an important anchoring point in the current research on the alleged embodiment of meaning comprehension, even if we would rather count on more definitive threshold points (Hauk, 2016).

Word processing data are mainly based on written word processing, but spoken words are processed quite similarly, if slightly faster (Leonard, Baud, Sjerps, & Chang, 2016; Pulvermüller, Shtyrov, & Ilmoniemi, 2005; Shtyrov, Hauk, & Pulvermüller, 2004). The bigger take-home messages would be: (1) the processing of meaning might only start at around 160 ms after word onset, and (2) processes outside of meaning comprehension might only start at around 270 ms after words onset. These working references must be taken with some caution because particular semantic effects have been found at different stages (e.g., the conceptual modality switch, as in Hald, Marshall, Janssen, & Garnham, 2011; Collins, Pecher, Zeelenberg, & Coulson, 2011). Indeed, in an influential critique of blooming findings on embodiment, Mahon and Caramazza (2008) argued that even early effects might possibly be explained in terms of non-embodied processing. They contended that working memory processes that were ancillary rather than semantic could be quickly engaged with the function of ‘colouring’ a concept, not building it up. Yet further, neither do we have absolute certainty on the later section of the time course. As Hauk (2016) reviews, the different stages likely overlap at certain points, with different degrees of relevance. For instance, lexical processing may continue even once semantic processing has started, but would naturally become less relevant. Indeed, the relation among these processes is likely more of a continuum than a set of clear-cut modules. In sum, it seems that much of the cause why the current topic does not quite get resolved is the fundamental lacunae we have on the time course of meaning comprehension in language.



```
  <Nodes>
    <string>1/Raw Data</string>
    <string>1/Raw Data/labels</string>
    <string>1/Raw Data/labels/positions</string>
    <string>1/Raw Data/labels/positions/rerefRM</string>
    <string>1/Raw Data/labels/positions/rerefRM/TotalMatch</string>
    <string>1/Raw Data/labels/positions/rerefRM/TotalMatch/OcularCorrection</string>
    <string>1/Raw Data/labels/positions/rerefRM/TotalMatch/OcularCorrection/baselinecorr</string>
    <string>1/Raw Data/labels/positions/rerefRM/TotalMatch/OcularCorrection/baselinecorr/baselinecorr_artif</string>
    <string>1/Raw Data/labels/positions/rerefRM/TotalMatch/OcularCorrection/baselinecorr/baselinecorr_artif/minave_TotalMatch</string>
    <string>1/Raw Data/labels/positions/rerefRM/EmbodiedMismatch</string>
    <string>1/Raw Data/labels/positions/rerefRM/EmbodiedMismatch/OcularCorrection</string>
    <string>1/Raw Data/labels/positions/rerefRM/EmbodiedMismatch/OcularCorrection/baselinecorr</string>
    <string>1/Raw Data/labels/positions/rerefRM/EmbodiedMismatch/OcularCorrection/baselinecorr/baselinecorr_artif</string>
    <string>1/Raw Data/labels/positions/rerefRM/EmbodiedMismatch/OcularCorrection/baselinecorr/baselinecorr_artif/minave_EmbodiedMismatch</string>
    <string>1/Raw Data/labels/positions/rerefRM/TotalMismatch</string>
    <string>1/Raw Data/labels/positions/rerefRM/TotalMismatch/OcularCorrection</string>
    <string>1/Raw Data/labels/positions/rerefRM/TotalMismatch/OcularCorrection/baselinecorr</string>
    <string>1/Raw Data/labels/positions/rerefRM/TotalMismatch/OcularCorrection/baselinecorr/baselinecorr_artif</string>
    <string>1/Raw Data/labels/positions/rerefRM/TotalMismatch/OcularCorrection/baselinecorr/baselinecorr_artif/minave_TotalMismatch</string>
  </Nodes>
```


References



